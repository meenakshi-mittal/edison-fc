{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W1zf6pRXeE50",
        "wUqDYaTkij87",
        "NIry9T8JlGp_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flashtext"
      ],
      "metadata": {
        "id": "VXZvyDEutYIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import ast\n",
        "import math\n",
        "import nltk\n",
        "import hashlib\n",
        "import flashtext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8Kpa3wTSlQqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I23yew86clwO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = \"fa23\""
      ],
      "metadata": {
        "id": "5h1VXeFMgGJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_id = f\"data8_{m}\""
      ],
      "metadata": {
        "id": "jbDVTa9Vr7ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_turn_class_id = f\"data8_{m}_multiturn\""
      ],
      "metadata": {
        "id": "ro2vO5En6AJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/MyDrive/EdSupport/Deployment/Ed_Data_Processing/Data'"
      ],
      "metadata": {
        "id": "4aSkOfBOc61n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SGwP6HxaPQUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1 - anonymization"
      ],
      "metadata": {
        "id": "PWxiHEF5amnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threads = pd.read_json(data_dir + \"/data (phase 0)/\" + class_id + \"/data.json\")"
      ],
      "metadata": {
        "id": "3vhhq5F6huhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anonymization"
      ],
      "metadata": {
        "id": "LQVuDwp7d-Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anonymize(df):\n",
        "    \"\"\"\n",
        "    Substitutes the username of each thread/comment with a unique identifier\n",
        "    :param df: a dataframe containing multiple threads/comments with user and thread metadata.\n",
        "    \"\"\"\n",
        "    if df.shape[0] != 0:\n",
        "        df[\"user_id\"] = df[\"user\"].apply(user_to_id)\n",
        "        df[\"user_role\"] = df[\"user\"].apply(lambda s: s[\"role\"])\n",
        "        df.drop(columns=[\"user\"], inplace=True)\n",
        "        if \"answers\" in df.columns:\n",
        "            for answers in df[\"answers\"]:\n",
        "                if type(answers) is not float:\n",
        "                    answer_df = pd.DataFrame(answers)\n",
        "                    anonymize(answer_df)\n",
        "                    answer_index = 0\n",
        "                    for answer in answers:\n",
        "                        answer[\"user_id\"] = answer_df.loc[answer_index, \"user_id\"]\n",
        "                        answer[\"user_role\"] = answer_df.loc[answer_index, \"user_role\"]\n",
        "                        del answer[\"user\"]\n",
        "                        answer_index += 1\n",
        "        if \"comments\" in df.columns:\n",
        "            for comments in df[\"comments\"]:\n",
        "                comment_df = pd.DataFrame(comments)\n",
        "                anonymize(comment_df)\n",
        "                comment_index = 0\n",
        "                for comment in comments:\n",
        "                    comment[\"user_id\"] = comment_df.loc[comment_index, \"user_id\"]\n",
        "                    comment[\"user_role\"] = comment_df.loc[comment_index, \"user_role\"]\n",
        "                    del comment[\"user\"]\n",
        "                    comment_index += 1"
      ],
      "metadata": {
        "id": "ByRG61_5_0fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_to_id(user):\n",
        "    \"\"\"\n",
        "    Assigns a unique 12-digit identifier to each user.\n",
        "    :param user: user metadata, including user name, email, role.\n",
        "    :return: unique identifier of the user.\n",
        "    \"\"\"\n",
        "    m = hashlib.md5()\n",
        "    m.update(user[\"email\"].encode('utf-8'))\n",
        "    user_id = str(int(m.hexdigest(), 16))[0:12]\n",
        "\n",
        "    return user_id"
      ],
      "metadata": {
        "id": "Ck3DcEFLwmEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymize(threads)"
      ],
      "metadata": {
        "id": "5FoSjOP3woRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving anonymized data"
      ],
      "metadata": {
        "id": "PDb18xOSdmjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_dir + \"/data (phase 1)/\" + multi_turn_class_id):\n",
        "  os.mkdir(data_dir + \"/data (phase 1)/\" + multi_turn_class_id)\n",
        "\n",
        "threads.to_json(data_dir + \"/data (phase 1)/\" + multi_turn_class_id + \"/data_anonymized.json\", index=False)"
      ],
      "metadata": {
        "id": "4xIf8tdnwxGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preliminary structuring and cleaning"
      ],
      "metadata": {
        "id": "hj3ffbTZeAVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threads = pd.read_json(data_dir + \"/data (phase 1)/\" + multi_turn_class_id + \"/data_anonymized.json\")\n",
        "print(len(threads))\n",
        "threads"
      ],
      "metadata": {
        "id": "Xg3SYfbeU-BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subthread_extractor(comment):\n",
        "    comment_data = {\n",
        "        \"text\": comment.get(\"text\"),\n",
        "        \"user_id\": comment.get(\"user_id\"),\n",
        "        \"user_role\": comment.get(\"user_role\"),\n",
        "        \"endorsed\": comment.get(\"endorsed\"),\n",
        "        \"document\": comment.get(\"document\"),\n",
        "        \"created_at\": comment.get(\"created_at\"),\n",
        "        \"follow_ups\": []\n",
        "    }\n",
        "    if comment.get(\"comments\"):\n",
        "        for c in comment.get(\"comments\"):\n",
        "            followup_comments = subthread_extractor(c)\n",
        "            comment_data[\"follow_ups\"].append(followup_comments)\n",
        "    if comment.get(\"answers\"):\n",
        "        for c in comment.get(\"answers\"):\n",
        "            followup_comments = subthread_extractor(c)\n",
        "            comment_data[\"follow_ups\"].append(followup_comments)\n",
        "    return comment_data"
      ],
      "metadata": {
        "id": "zM_m7soM8Utd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_conversations(comment, path=[], conversations=[], added_last=False):\n",
        "    current_path = path + [comment] if not added_last else path  # Append current comment to path unless it was just added\n",
        "\n",
        "    if comment['user_role'] == 'student' and not comment['endorsed']:\n",
        "        for follow_up in comment['follow_ups']:\n",
        "            if not (follow_up['user_role'] == 'student' and not follow_up['endorsed']):\n",
        "                valid_convo = current_path + [follow_up]\n",
        "                conversations.append(valid_convo)\n",
        "                # Continue the conversation, marking the last admin/endorsed student comment as added\n",
        "                find_conversations(follow_up, valid_convo, conversations, added_last=True)\n",
        "            else:\n",
        "                find_conversations(follow_up, current_path, conversations)\n",
        "\n",
        "    else:\n",
        "        for follow_up in comment['follow_ups']:\n",
        "            find_conversations(follow_up, current_path, conversations)\n",
        "\n",
        "    for i in range(len(conversations)):\n",
        "        while conversations[i] and not (conversations[i][0]['user_role'] == 'student' and not conversations[i][0]['endorsed']):\n",
        "            conversations[i].pop(0)\n",
        "\n",
        "        for comment in conversations[i]:\n",
        "            comment.pop('follow_ups', None)\n",
        "\n",
        "    return conversations"
      ],
      "metadata": {
        "id": "dzNcxToc8UiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_table(df):\n",
        "\n",
        "    new_rows = []\n",
        "    for index, row in df.iterrows():\n",
        "        comment_dict = subthread_extractor(row)\n",
        "        convos = find_conversations(comment_dict, path=[], conversations=[], added_last=False)\n",
        "\n",
        "        for convo in convos:\n",
        "            if not (convo[0]['user_role'] == 'student' and not convo[0]['endorsed']):\n",
        "                convo.pop(0)\n",
        "            new_row = row.to_dict()\n",
        "            new_row['memory'] = convo\n",
        "            new_rows.append(new_row)\n",
        "\n",
        "    new_df = pd.DataFrame(new_rows)\n",
        "    return new_df\n",
        "\n",
        "threads = process_table(threads)\n",
        "threads.drop(columns=['url', 'answers', 'comments'], inplace=True)"
      ],
      "metadata": {
        "id": "Jc6le38GL6oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_remove_by_index(memory_list, index):\n",
        "    return memory_list.pop(index)\n",
        "\n",
        "questions = threads['memory'].apply(lambda x: extract_and_remove_by_index(x, -2))\n",
        "answers = threads['memory'].apply(lambda x: extract_and_remove_by_index(x, -1))\n",
        "\n",
        "threads['question'] = questions.apply(lambda x: x['text'])\n",
        "threads['document_q'] = questions.apply(lambda x: x['document'])\n",
        "threads['created_at'] = questions.apply(lambda x: x['created_at'])\n",
        "\n",
        "threads['answer'] = answers.apply(lambda x: x['text'])\n",
        "threads['document_a'] = answers.apply(lambda x: x['document'])\n",
        "\n",
        "threads = threads.rename(columns={'document': 'document_p'})\n",
        "threads[\"question\"] = threads[\"title\"] + \": \" + threads[\"question\"]\n",
        "\n",
        "\n",
        "\n",
        "# Display the updated DataFrame\n",
        "threads = threads[[\"type\",\"created_at\",\t\"category\",\t\"subcategory\",\t\"title\",\t\"text\",\t\"document_p\",\t\"memory\",\t\"question\",\t\"document_q\",\t\"answer\",\t\"document_a\"]]\n"
      ],
      "metadata": {
        "id": "C-C-oArEd6is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving initially cleaned data"
      ],
      "metadata": {
        "id": "sa_Qe-_ndvtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_dir + \"/data (phase 3)/\" + multi_turn_class_id):\n",
        "  os.mkdir(data_dir + \"/data (phase 3)/\" + multi_turn_class_id)\n",
        "\n",
        "threads.to_csv(data_dir + \"/data (phase 3)/\" + multi_turn_class_id + \"/data_anonymized_cleaned.csv\", index=False)"
      ],
      "metadata": {
        "id": "h1_7zqzQxaOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 4 - removing threads with confidential information"
      ],
      "metadata": {
        "id": "NIry9T8JlGp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading cleaned data from phase 3."
      ],
      "metadata": {
        "id": "k3uKpDadleGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data = pd.read_csv(data_dir + \"/data (phase 3)/\" + multi_turn_class_id + \"/data_anonymized_cleaned.csv\")\n",
        "\n",
        "qa_data[\"memory\"] = qa_data[\"memory\"].apply(ast.literal_eval)\n",
        "qa_data"
      ],
      "metadata": {
        "id": "x3zR-Ixhlb9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing names appearing in the Ed roster."
      ],
      "metadata": {
        "id": "KcLznL15FfFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "english_stopwords = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "LkEXAu8AKcUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roster = pd.read_csv(data_dir + \"/data (phase 0)/\" + class_id + \"/roster.csv\")\n",
        "roster = roster[~roster[\"Name\"].isna()]\n",
        "\n",
        "staff_names = roster[roster[\"Role\"] != \"student\"][\"Name\"]\n",
        "student_names = roster[roster[\"Role\"] == \"student\"][\"Name\"]\n",
        "\n",
        "staff_first_names = staff_names.str.split().str[0]\n",
        "staff_last_names = staff_names.str.split().str[1:].apply(lambda x: \" \".join(x))\n",
        "\n",
        "student_first_names = student_names.str.split().str[0]\n",
        "student_last_names = student_names.str.split().str[1:].apply(lambda x: \" \".join(x))\n",
        "\n",
        "staff_first_names = list(set(staff_first_names) - english_stopwords)\n",
        "student_first_names = list(set(student_first_names) - english_stopwords)"
      ],
      "metadata": {
        "id": "c4sQGTJjJZc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_processor = flashtext.KeywordProcessor()\n",
        "keyword_dictionary = {\n",
        "    \"Staff x\" : staff_first_names,\n",
        "    \"Student x\" : student_first_names\n",
        "}\n",
        "keyword_processor.add_keywords_from_dict(keyword_dictionary)\n",
        "\n",
        "for column in tqdm(qa_data.columns):\n",
        "    if column != \"memory\":\n",
        "        qa_data[column][qa_data[column].isna()] = \"\"\n",
        "        replaced = []\n",
        "        for i in list(qa_data[column]):\n",
        "            try:\n",
        "                one_replace = keyword_processor.replace_keywords(i)\n",
        "                replaced.append(one_replace)\n",
        "            except:\n",
        "                print(f\"ERROR: following text could not be parsed: \\n{i}\\n\")\n",
        "                print(f\"If there are any student/staff names contained in this text, please manually remove them.\")\n",
        "                replaced.append(i)\n",
        "        qa_data[column] = replaced\n"
      ],
      "metadata": {
        "id": "P1OwypDqJggE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dictionary(dictionary):\n",
        "    for key, value in dictionary.items():\n",
        "        if isinstance(value, str):\n",
        "            dictionary[key] = keyword_processor.replace_keywords(value)\n",
        "    return dictionary\n",
        "\n",
        "qa_data[\"memory\"] = qa_data[\"memory\"].apply(lambda mem: [process_dictionary(m) for m in mem])"
      ],
      "metadata": {
        "id": "kL5tRX6_F6SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing points that contain \"dsp\", \"extnesion\", \"extenuating\" words"
      ],
      "metadata": {
        "id": "wu94x92oGgbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = r\"(dsp)|(extension)|(extenuating)|(#)\""
      ],
      "metadata": {
        "id": "h6s8v_CoIGnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in qa_data.columns:\n",
        "  if column in [\"question\", \"answer\"]:\n",
        "    qa_data = qa_data[~qa_data[column].str.lower().str.contains(keywords)]\n",
        "\n",
        "  elif column == \"memory\":\n",
        "    # qa_data = qa_data[~qa_data[column].apply(lambda x: sum([bool(re.search(keywords, m[0])) for m in x]) > 0)]\n",
        "    pattern = re.compile(keywords)\n",
        "    qa_data = qa_data[~qa_data[column].apply(lambda x: any(pattern.search(str(value)) for m in x for value in m.values()))]\n"
      ],
      "metadata": {
        "id": "4b_IP4zMHo2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the files."
      ],
      "metadata": {
        "id": "hqw_wMtYmexr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_dir + \"/data_(phase_4)/\" + multi_turn_class_id):\n",
        "  os.mkdir(data_dir + \"/data_(phase_4)/\" + multi_turn_class_id)\n",
        "\n",
        "qa_data.to_csv(data_dir + \"/data_(phase_4)/\" + multi_turn_class_id + \"/qa.csv\", index=False)"
      ],
      "metadata": {
        "id": "xcw4qr0imeFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data"
      ],
      "metadata": {
        "id": "hcUfs5atiQJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
